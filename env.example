# LLM Configuration
# Copy this file to .env and fill in your values

# API Key (required for cloud services like OpenAI, optional for local Ollama)
LLM_API_KEY=sk-your-api-key-here

# Base URL (optional, defaults to OpenAI)
# For OpenAI (default):
#LLM_BASE_URL=https://api.openai.com/v1/chat/completions

# For Ollama (local):
#LLM_BASE_URL=http://localhost:11434/v1/chat/completions

# For Azure OpenAI:
#LLM_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions?api-version=2024-02-01

# For LM Studio:
#LLM_BASE_URL=http://localhost:1234/v1/chat/completions

# Model name (optional, defaults to gpt-4-turbo-preview)
LLM_MODEL=gpt-4-turbo-preview

# Temperature: controls randomness (0.0-1.0)
# Lower values (0.1-0.3) for deterministic parsing
# Higher values (0.7-1.0) for creative responses
LLM_TEMPERATURE=0.7

# Max tokens: maximum response length
LLM_MAX_TOKENS=4096

# Skip SSL certificate verification (for self-hosted/private LLMs with self-signed certificates)
# SECURITY WARNING: Only use this for development/testing with trusted private LLMs
# Accepts: true/false, yes/no, 1/0
LLM_SKIP_SSL_VERIFY=false

# Debug mode: enable detailed request/response logging
# Useful for troubleshooting and seeing what's sent to/from the LLM
# For thinking models (like o1), will also log the reasoning process
# Accepts: true/false, yes/no, 1/0
LLM_DEBUG=false

# Examples for different providers:

# OpenAI GPT-4:
# LLM_API_KEY=sk-...
# LLM_MODEL=gpt-4-turbo-preview

# OpenAI o1 (thinking model):
# LLM_API_KEY=sk-...
# LLM_MODEL=o1-preview
# LLM_DEBUG=true  # Enable to see reasoning process

# OpenAI GPT-3.5 (cheaper):
# LLM_API_KEY=sk-...
# LLM_MODEL=gpt-3.5-turbo

# Azure OpenAI:
# LLM_API_KEY=your-azure-key
# LLM_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-02-01
# LLM_MODEL=gpt-4

# Ollama (local, free):
# LLM_BASE_URL=http://localhost:11434/v1/chat/completions
# LLM_MODEL=llama2
# (no API key needed)

# Private/Self-hosted LLM with self-signed certificate:
# LLM_BASE_URL=https://your-internal-llm.company.com/v1/chat/completions
# LLM_API_KEY=your-key
# LLM_MODEL=your-model
# LLM_SKIP_SSL_VERIFY=true

